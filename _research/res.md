---
title: "Research"
collection: teaching
permalink: /research/
---

## Research Interests: 

* Explainable AI
  + Self-Explainable Architectures for CV and NLP tasks
  + Explaining Vision Language Models and their decisions
* Understanding the limitations of Vision Language Models
  + Visual perception
  + Difference/Similarity comprehension
 
During my Master's, I worked on Reinforcement Learning (RL) and Robotics, where my goal was to help robotic platforms acquire complex skills via RL.


## Research To Date:

As part of my Ph.D. research, I am working on self-explainable and editable models for downstream CV/NLP tasks. More specifically, my research centers on the interpretability of minimal transformer layers (attention bottlenecks). I aim to use these bottlenecks so users can edit, debug and intervene in AI's decision making.

<!-- ## Proposed  Research

In the era of Transformers, renowned for their efficacy in vision and language tasks, the challenge of explainability becomes very important. These models, while powerful, often operate as black boxes, hindering comprehension by human users. Recognizing this, I propose integrating self-explainable models to demystify the inner workings of transformers. To this end, I aim to incorporate an attention bottleneck module within transformers. This proposed bottleneck enhances the explainability of these models and facilitates their editability, thus fostering greater transparency and usability. -->


